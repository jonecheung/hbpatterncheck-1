# System Architecture Documentation

Complete technical architecture of the Hemoglobin Pattern Disease Chatbot.

---

## Table of Contents

1. [Overview](#overview)
2. [Data Flow](#data-flow)
3. [Component Details](#component-details)
4. [Technology Stack](#technology-stack)
5. [Phase 1 vs Phase 2](#phase-1-vs-phase-2)
6. [API Reference](#api-reference)

---

## Overview

The HB Pattern Chatbot is a **Retrieval-Augmented Generation (RAG)** system that allows natural language queries over a medical database of hemoglobin pattern disease cases.

### Key Features

- **Semantic Search**: Find relevant cases based on meaning, not just keywords
- **Local LLM**: Responses generated by Ollama Llama3 (runs on your machine)
- **Privacy-First**: No data leaves your computer (Phase 1 optional cloud, Phase 2 fully local)
- **Citation Support**: Every response includes source page numbers
- **Scalable**: Can handle thousands of patient records

---

## Data Flow

### Ingestion Pipeline (One-Time Setup)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  1. PDF Document                                         ‚îÇ
‚îÇ     ‚Üì                                                    ‚îÇ
‚îÇ  2. PyMuPDF Extraction                                   ‚îÇ
‚îÇ     ‚îú‚îÄ‚Üí Text Content (46 pages)                         ‚îÇ
‚îÇ     ‚îî‚îÄ‚Üí Images (chromatographs) ‚Üí GPT-4V Descriptions   ‚îÇ
‚îÇ     ‚Üì                                                    ‚îÇ
‚îÇ  3. Text Chunking (RecursiveCharacterTextSplitter)      ‚îÇ
‚îÇ     - chunk_size: 1000 characters                        ‚îÇ
‚îÇ     - chunk_overlap: 200 characters                      ‚îÇ
‚îÇ     - Result: 62 chunks                                  ‚îÇ
‚îÇ     ‚Üì                                                    ‚îÇ
‚îÇ  4. Embedding Generation (sentence-transformers)         ‚îÇ
‚îÇ     - Model: all-MiniLM-L6-v2                           ‚îÇ
‚îÇ     - Dimension: 384                                     ‚îÇ
‚îÇ     - Each chunk ‚Üí 384-dimensional vector                ‚îÇ
‚îÇ     ‚Üì                                                    ‚îÇ
‚îÇ  5. Vector Storage (ChromaDB)                            ‚îÇ
‚îÇ     - Persistent database: ./vector_db/chroma_storage   ‚îÇ
‚îÇ     - Includes metadata: page, type, source              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Query Pipeline (Runtime)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  User Input: "What are HbE disease patterns?"           ‚îÇ
‚îÇ     ‚Üì                                                    ‚îÇ
‚îÇ  1. Query Embedding                                      ‚îÇ
‚îÇ     - Same model as ingestion (all-MiniLM-L6-v2)        ‚îÇ
‚îÇ     - Query ‚Üí 384-dimensional vector                     ‚îÇ
‚îÇ     ‚Üì                                                    ‚îÇ
‚îÇ  2. Vector Similarity Search (ChromaDB)                  ‚îÇ
‚îÇ     - Cosine similarity between query and all docs       ‚îÇ
‚îÇ     - Retrieve top-k most similar (k=5)                  ‚îÇ
‚îÇ     - Filter by threshold (>0.7)                         ‚îÇ
‚îÇ     ‚Üì                                                    ‚îÇ
‚îÇ  3. Context Building                                     ‚îÇ
‚îÇ     - Combine retrieved chunks                           ‚îÇ
‚îÇ     - Add page numbers and metadata                      ‚îÇ
‚îÇ     - Format for LLM consumption                         ‚îÇ
‚îÇ     ‚Üì                                                    ‚îÇ
‚îÇ  4. LLM Generation (Ollama Llama3)                       ‚îÇ
‚îÇ     - System prompt + Context + User question            ‚îÇ
‚îÇ     - Temperature: 0.7                                   ‚îÇ
‚îÇ     - Max tokens: 500                                    ‚îÇ
‚îÇ     ‚Üì                                                    ‚îÇ
‚îÇ  5. Response with Citations                              ‚îÇ
‚îÇ     - Natural language answer                            ‚îÇ
‚îÇ     - Source page numbers                                ‚îÇ
‚îÇ     - Similarity scores                                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Component Details

### 1. PDF Extractor (`src/1_extract_pdf.py`)

**Purpose:** Extract text and images from the source PDF.

**Technology:** PyMuPDF (fitz)

**Process:**
1. Open PDF document
2. Iterate through each page
3. Extract text using `.get_text()`
4. Extract images using `.get_images()` and `.extract_image()`
5. Save to JSON with metadata

**Output Files:**
- `data/pdf_text.json`: Text content with page numbers
- `data/extracted_images/*.png`: Chromatograph images
- `data/image_metadata.json`: Image dimensions and locations

**Performance:** ~30 seconds for 46-page PDF

---

### 2. Image Describer (`src/2_describe_images.py`)

**Purpose:** Use AI to describe chromatograph patterns in text.

**Phase 1 Technology:** OpenAI GPT-4V (cloud API)
**Phase 2 Technology:** LLaVA (local model)

**Process:**
1. Load all extracted images
2. For each image:
   - Encode to base64
   - Send to GPT-4V with specialized prompt
   - Receive detailed technical description
3. Cache descriptions to avoid reprocessing
4. Save to JSON

**Specialized Prompt:**
```
Analyze this hemoglobin chromatograph image in detail. Provide a technical description including:
1. Peak patterns and their positions (if visible)
2. Relative peak heights and intensities
3. Any abnormal or unusual patterns
4. Retention times or time markers (if visible)
5. Overall pattern classification or characteristics
6. Any diagnostic indicators visible
```

**Output File:**
- `data/image_descriptions.json`

**Cost:** ~$0.01 per image (Phase 1 only, one-time)

**Note:** Currently skipped as no images were extracted from PDF.

---

### 3. Vector Database Builder (`src/3_build_vectordb.py`)

**Purpose:** Convert text and descriptions into searchable vectors.

**Technology:** 
- ChromaDB (vector database)
- sentence-transformers (embedding model)
- LangChain (text splitting)

**Process:**

**Step 1: Text Chunking**
```python
RecursiveCharacterTextSplitter(
    chunk_size=1000,
    chunk_overlap=200,
    separators=["\n\n", "\n", ". ", " ", ""]
)
```
- Splits at logical boundaries (paragraphs, sentences)
- Overlap ensures context isn't lost
- Result: 62 chunks from 46 pages

**Step 2: Embedding Generation**
```python
SentenceTransformer('all-MiniLM-L6-v2')
embedding = model.encode(text)
# Output: 384-dimensional vector
```
- Each chunk ‚Üí numerical vector
- Similar meanings ‚Üí similar vectors
- Enables semantic search

**Step 3: Database Storage**
```python
collection.add(
    documents=texts,
    embeddings=embeddings_list,
    metadatas=metadatas,
    ids=ids
)
```

**Metadata Schema:**
```python
{
    "type": "text" | "image_description",
    "page": 1-46,
    "chunk_index": 0-N,
    "source_file": "Abnormal Hb Pattern(pdf).pdf",
    "image_file": "page_X_img_Y.png"  # if image
}
```

**Output:** 
- Persistent database at `vector_db/chroma_storage/`
- SQLite file + vector indices
- ~10-50MB total size

**Performance:** 2-5 minutes depending on hardware

---

### 4. Query Engine (`src/4_query_engine.py`)

**Purpose:** RAG pipeline connecting retrieval to LLM.

**Key Functions:**

#### 4.1 `retrieve_relevant_cases(query, k=5)`

```python
# 1. Embed query
query_embedding = embedding_model.encode(query)

# 2. Search vector database
results = collection.query(
    query_embeddings=[query_embedding],
    n_results=k
)

# 3. Return documents with scores
return results['documents'], results['metadatas'], results['distances']
```

**Similarity Metric:** Cosine similarity
- 1.0 = identical
- 0.0 = orthogonal
- Threshold: 0.7 (configurable)

#### 4.2 `build_context(retrieved_docs)`

```python
context = ""
for i, (doc, meta) in enumerate(zip(docs, metas)):
    context += f"[Source {i+1}, Page {meta['page']}]\n{doc}\n\n"
return context
```

Formats retrieved chunks for LLM consumption.

#### 4.3 `query_with_rag(user_query)`

```python
# 1. Retrieve relevant cases
docs, metas, scores = retrieve_relevant_cases(query)

# 2. Build context
context = build_context(docs, metas)

# 3. Create prompt
prompt = f"""
System: You are a medical AI assistant specializing in hemoglobin pattern diseases.

Context from patient database:
{context}

User question: {user_query}

Provide accurate medical information based only on the context above.
Cite page numbers when referencing specific cases.
"""

# 4. Call Ollama
response = ollama.chat(
    model='llama3',
    messages=[{'role': 'user', 'content': prompt}]
)

# 5. Return response with sources
return response, sources
```

---

### 5. Streamlit UI (`src/5_app.py`)

**Purpose:** User-friendly web interface.

**Features:**

#### Main Chat Interface
- Message history (session state)
- Text input box
- Send button
- Clear conversation

#### Sidebar
- **Number of results (k):** 1-10 slider
- **Show sources:** Toggle
- **Search mode:** Text / Image / Hybrid
- **Advanced settings:**
  - Temperature: 0.0-1.0
  - Max tokens: 100-1000
  - Similarity threshold: 0.5-0.9

#### Results Display
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ üî¨ Hemoglobin Pattern Disease Chatbot  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ User: What are HbE disease patterns?    ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ Assistant:                              ‚îÇ
‚îÇ Based on the database, HbE disease      ‚îÇ
‚îÇ shows the following characteristics...  ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ üìö Sources:                             ‚îÇ
‚îÇ   [1] Page 23 (similarity: 0.89)        ‚îÇ
‚îÇ   [2] Page 24 (similarity: 0.85)        ‚îÇ
‚îÇ   [3] Page 30 (similarity: 0.82)        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### Example Queries
Pre-populated buttons:
- "What are characteristics of HbE disease?"
- "Show cases with elevated HbA2"
- "Find beta thalassemia patterns"
- "What retention times indicate abnormal patterns?"

---

## Technology Stack

### Core Technologies

| Component | Technology | Version | Purpose |
|-----------|-----------|---------|---------|
| **Language** | Python | 3.12 | Core programming |
| **Vector DB** | ChromaDB | 0.4.22 | Store embeddings |
| **Embeddings** | sentence-transformers | 2.3.1 | Text ‚Üí vectors |
| **Embedding Model** | all-MiniLM-L6-v2 | - | 384-dim embeddings |
| **LLM** | Ollama Llama3 | 8B | Local chat model |
| **PDF Parser** | PyMuPDF | 1.23.8 | Extract content |
| **Web UI** | Streamlit | 1.29.0 | User interface |
| **Framework** | LangChain | 0.1.0 | RAG orchestration |

### Dependencies Tree

```
hbpatterncheck/
‚îÇ
‚îú‚îÄ‚îÄ Data Processing
‚îÇ   ‚îú‚îÄ‚îÄ pymupdf (PDF parsing)
‚îÇ   ‚îú‚îÄ‚îÄ pypdf (backup parser)
‚îÇ   ‚îî‚îÄ‚îÄ pillow (image processing)
‚îÇ
‚îú‚îÄ‚îÄ Embeddings & Search
‚îÇ   ‚îú‚îÄ‚îÄ sentence-transformers
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ transformers
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ torch
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ numpy
‚îÇ   ‚îú‚îÄ‚îÄ chromadb
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sqlite3
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ hnswlib
‚îÇ   ‚îî‚îÄ‚îÄ langchain
‚îÇ
‚îú‚îÄ‚îÄ LLM & API
‚îÇ   ‚îú‚îÄ‚îÄ ollama-python
‚îÇ   ‚îú‚îÄ‚îÄ openai (Phase 1 optional)
‚îÇ   ‚îî‚îÄ‚îÄ python-dotenv
‚îÇ
‚îî‚îÄ‚îÄ Web Interface
    ‚îú‚îÄ‚îÄ streamlit
    ‚îú‚îÄ‚îÄ pyyaml
    ‚îî‚îÄ‚îÄ tqdm (progress bars)
```

---

## Phase 1 vs Phase 2

### Phase 1: Hybrid (Current)

**Cloud Components:**
- GPT-4V for image descriptions (optional, one-time)

**Local Components:**
- Text embeddings (sentence-transformers)
- Vector database (ChromaDB)
- LLM chat (Ollama Llama3)
- Web UI (Streamlit)

**Pros:**
- ‚úÖ Best image description quality
- ‚úÖ Quick setup
- ‚úÖ Lower hardware requirements

**Cons:**
- ‚ö†Ô∏è One-time API cost ($0-10)
- ‚ö†Ô∏è Requires internet for image processing

**Cost:** ~$0-10 one-time, then $0/month

---

### Phase 2: Fully Local

**All Local Components:**
- LLaVA (local vision model)
- CLIP (image embeddings)
- sentence-transformers (text embeddings)
- ChromaDB (vector database)
- Ollama Llama3 (LLM)
- Streamlit (UI)

**Pros:**
- ‚úÖ 100% private (HIPAA compliant)
- ‚úÖ Works offline
- ‚úÖ Zero ongoing costs
- ‚úÖ True visual similarity search (CLIP)

**Cons:**
- ‚ö†Ô∏è Requires more setup time
- ‚ö†Ô∏è Higher hardware requirements (16GB+ RAM)
- ‚ö†Ô∏è Slower image processing

**Cost:** $0/month, ~12GB storage

---

## API Reference

### Configuration (`config/config.yaml`)

```yaml
phase: 1  # 1 for hybrid, 2 for fully local

pdf:
  source: "data/Abnormal Hb Pattern(pdf).pdf"
  output_text: "data/pdf_text.json"
  output_images: "data/extracted_images/"

embeddings:
  model: "sentence-transformers/all-MiniLM-L6-v2"
  dimension: 384

vectordb:
  type: "chroma"
  persist_directory: "./vector_db/chroma_storage"
  collection_name: "hb_patterns"

chunking:
  chunk_size: 1000
  chunk_overlap: 200

vision:
  phase1_model: "gpt-4-vision-preview"
  phase2_model: "llava:13b"

llm:
  model: "llama3"
  temperature: 0.7
  max_tokens: 500

retrieval:
  top_k: 5
  similarity_threshold: 0.7
  search_type: "similarity"  # or "mmr"

ui:
  title: "Hemoglobin Pattern Disease Chatbot"
  page_icon: "üî¨"
```

### Environment Variables (`.env`)

```bash
# Required for Phase 1 image descriptions
OPENAI_API_KEY=sk-...

# Optional overrides
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
CHROMA_DB_PATH=./vector_db/chroma_storage
```

### Python Module Structure

```python
# src/utils.py
load_config() -> Dict  # Load YAML config
ensure_directories()    # Create required directories
get_project_root() -> Path  # Get root directory
format_sources(docs) -> str  # Format citations

# src/1_extract_pdf.py
extract_text_from_pdf(pdf_path) -> List[Dict]
extract_images_from_pdf(pdf_path, output_dir) -> List[Dict]

# src/2_describe_images.py
describe_image_with_gpt4v(image_path, client) -> str
process_all_images(image_dir, cache_file) -> Dict[str, str]

# src/3_build_vectordb.py
chunk_text(text_data, chunk_size, overlap) -> List[Dict]
build_vector_database(documents, config) -> Collection

# src/4_query_engine.py
retrieve_relevant_cases(query, k=5) -> Tuple[List, List, List]
build_context(docs, metas) -> str
query_with_rag(user_query) -> Tuple[str, str]

# src/5_app.py
# Streamlit app (no exports, run with streamlit run)
```

---

## Performance Characteristics

### Ingestion (One-Time)

| Step | Time | Hardware Impact |
|------|------|-----------------|
| PDF Extraction | 30 sec | CPU: Low, RAM: 500MB |
| Image Description (GPT-4V) | 2-3 sec/image | Network only |
| Text Chunking | 5 sec | CPU: Low, RAM: 200MB |
| Embedding Generation | 2-5 min | CPU: High, RAM: 2GB |
| Vector DB Build | 30 sec | Disk I/O, RAM: 1GB |
| **Total** | **5-10 min** | **Peak RAM: 2GB** |

### Query (Runtime)

| Step | Time | Notes |
|------|------|-------|
| Query Embedding | 100ms | CPU bound |
| Vector Search | 50ms | Fast HNSW index |
| Context Building | 10ms | String operations |
| LLM Generation | 2-3 sec | Ollama Llama3 |
| **Total** | **3-5 sec** | Acceptable UX |

### Optimization Tips

**Speed Up Embeddings:**
- Use GPU: Install `torch` with CUDA
- Smaller model: `all-MiniLM-L6-v2` (fast) vs `all-mpnet-base-v2` (accurate)
- Batch processing: Process 100 chunks at once

**Speed Up LLM:**
- Smaller model: `llama3.2:1b` vs `llama3:8b`
- Reduce max_tokens: 300 instead of 500
- Lower temperature: 0.3 instead of 0.7 (less creative)

**Reduce Memory:**
- Smaller embedding model
- Process in smaller batches
- Close other applications

---

## Security & Privacy

### Data Protection

**Phase 1 (Hybrid):**
- ‚úÖ Text stored locally (ChromaDB)
- ‚úÖ Embeddings stored locally
- ‚úÖ LLM runs locally (Ollama)
- ‚ö†Ô∏è Images sent to OpenAI (one-time, optional)

**Phase 2 (Fully Local):**
- ‚úÖ Everything local
- ‚úÖ No internet required
- ‚úÖ HIPAA compliant
- ‚úÖ No data ever leaves machine

### API Keys

- Stored in `.env` (gitignored)
- Never committed to version control
- Only used for GPT-4V (optional)

### File Permissions

```bash
# Secure .env file
chmod 600 .env

# Public files
chmod 644 config/*.yaml
chmod 755 src/*.py
```

---

## Scalability

### Current Limits

- **Documents:** 62 chunks (from 46 pages)
- **Vector DB size:** ~50MB
- **Query time:** 3-5 seconds
- **Concurrent users:** 1 (Streamlit default)

### Scaling Options

**More Documents (1000s of cases):**
- ChromaDB handles millions of vectors
- May need to increase batch size
- Consider pagination in UI

**Multiple Users:**
- Deploy on server
- Use Streamlit Cloud or Docker
- Add authentication

**Better Performance:**
- GPU acceleration for embeddings
- Larger embedding model for accuracy
- FAISS instead of ChromaDB for speed

---

## Maintenance

### Regular Tasks

**Weekly:**
- Check disk space (`du -sh vector_db/`)
- Monitor query performance
- Review logs for errors

**Monthly:**
- Update Ollama models: `ollama pull llama3`
- Backup vector database
- Test with new queries

**As Needed:**
- Add new PDF pages ‚Üí Re-run ingestion
- Tune similarity threshold
- Update prompts for better responses

### Backup Strategy

```bash
# Backup vector database
tar -czf backup_vectordb_$(date +%Y%m%d).tar.gz vector_db/

# Backup source data
tar -czf backup_data_$(date +%Y%m%d).tar.gz data/

# Backup configuration
cp config/config.yaml config/config.yaml.backup
```

---

## Future Enhancements

### Planned Features

1. **Multi-language support** (translate queries)
2. **Image upload for similarity search** (Phase 2)
3. **Export results to PDF**
4. **Query history and favorites**
5. **Advanced filters** (by disease type, date range)
6. **Batch query mode** (process multiple queries)
7. **API endpoint** (REST API for integration)

### Research Directions

- Fine-tune embedding model on medical data
- Custom prompt engineering for hemoglobin patterns
- Hybrid search (keyword + semantic)
- Graph-based knowledge extraction
- Automatic report generation

---

## Conclusion

This architecture provides a solid foundation for semantic search over medical databases with strong privacy guarantees and good performance. The modular design allows easy upgrades and customization as needs evolve.


